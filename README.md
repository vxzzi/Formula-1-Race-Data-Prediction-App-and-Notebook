# Formula-1-Race-Data-Prediction-App-and-Notebook
This repository contains end-to-end modelling of a Formula 1 average lap time prediction app that can be containerised using docker.

I began by performing some exploratory data analysis on the dataset in order to get a better understanding of the shape and distribution of the features. I also checked for and removed any missing and duplicate value present in the dataset as part of pre-processing. I visualised the distribution of the target feature Avg_Lap_Time_Secs and noticed that it was somewhat similar to a gaussian distribution. This is important to note as some of the machine learning models applied in this end-to-end modelling exercise, such as linear regression and Bayesian ridge, operate under the assumption that the data is gaussian distributed. I also computed the spearman’s correlation of the numerical features in the dataset and visualised it as a heatmap in an attempt to depict the monotonic relationship between the predictors and the target feature. I observed that although the Driver_ID had the strongest positive correlation to the target feature, the correlation coefficient was too small arrive at a satisfactory conclusion of feature importance. Some identifier features were then dropped as a result of redundancy. That means, for instance, the Race_ID can be represented by Race_Name because either of them can be used as an identifier in the same context. 
I then wrote a function to detect rows containing outliers as some machine learning models such as linear regression and support vector machine are sensitive to these outliers and can be significantly impacted by them. I noticed that using the number of outliers found in the numerical features of the dataset was too large to simply remove from the dataset as they may contain useful information to be learned from. I then added a filter to drop only the rows that contained more than two outliers. Since there was no categorical variable with ordinal relationships, dummy variables were created for each level in the categories in preparation for machine learning. The data was then split into train and test data with the ratio 0.75:0.25 for training and evaluation of the machine learning model. 9 different machine learning models were trained with dataset and for some of the models that are strongly influenced by the gaussian assumption and/or are sensitive to outlier, the data had to be transformed into gaussian-like distribution before fitting it in the model by creating a pipeline. The models were trained and evaluated using the root mean squared error and R2 score metrics and the results were plotted on a graph. The random forest model had the best performance using the above metrics with a RMSE of 5.609 and R2 score of 0.895. Ten fold cross validation was carried out to ascertain the performance of the model on unseen data and the results were similar to the evaluation performed earlier which is a positive sign. A stacking ensemble learner made up of random forest, XGBoost and extremely randomized regressors was built using the training data but the result of the evaluation wasn’t as good as the random forest regressor model. The random forest model was then tuned by using a gridsearch algorithm and 10-fold cross validation to optimise five hyperparameters. 
The optimization was used to build a random forest regressor model with an R2 score of 0.882, which slightly outperformed the former (10-fold cross-validation R2 score of 0.877). Feature selection was then performed using the optimised model as a wrapper method and the results showed 10 most important features including the categorical variables Race_Name and Circuit_Name. These features were then passed through a pipeline of pre-processing before fitting them into the random forest regressor using the optimised hyperparameter and 10-fold cross validation. The results indicated a slight improvement with a RMSE of 5.524 and R2 score of 0.898 and the model was saved as an object. To conclude the end-to-end modelling, a simple app was created using flask, html, css and javascript and a Dockerfile was created for deployment. The purpose of this app is to predict the average lap time using input from 10 fields/features and the source code can be found on git.
